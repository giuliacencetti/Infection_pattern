{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'pr_school'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load C and obtain r and s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is an array of weights, I need to put it in a matrix shape to compute r and s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_r_s_indices(C,edgelist):\n",
    "    # put C in dict:\n",
    "    C_dict = {}\n",
    "    n = 0\n",
    "    for edge in edgelist:\n",
    "        C_dict[tuple(edge)] = C[n]\n",
    "        C_dict[tuple(edge[::-1])] = C[n+1]\n",
    "        n += 2\n",
    "    # verify:\n",
    "    if list(C_dict.values()) != list(C):\n",
    "        print('error')\n",
    "    nb_nodes = max(np.unique(list(C_dict.keys()))) + 1\n",
    "    # put C_dict in matrix:\n",
    "    C_mat = np.zeros((nb_nodes,nb_nodes))\n",
    "    for link in C_dict:\n",
    "        C_mat[link[0],link[1]] = C_dict[link]\n",
    "\n",
    "    # receiver index:\n",
    "    r = C_mat.sum(axis=0) # somma di ogni colonna\n",
    "    # spreader index:\n",
    "    s = C_mat.sum(axis=1) # somma di ogni riga\n",
    "\n",
    "    return r, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pairwise/' + dataset + '_strength_edgelist_pairwise_sorted_norm.pkl', 'rb') as f:\n",
    "    edgelist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.1\n",
    "if dataset == 'pr_school':\n",
    "    beta = 0.36\n",
    "    R0 = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Simple_model/code/results/inf_treeSIR/CL_mean_weighted_pr_school_beta_0.360_betaT_0.000_mu_0.10_init_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-38f4f8a7e847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../Simple_model/code/results/inf_treeSIR/CL_mean_weighted_%s_beta_%.3f_betaT_0.000_mu_%.2f_init_1.csv\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_C_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# verify:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medgelist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Progetti_post_doc/Infection_pattern-main/utils.py\u001b[0m in \u001b[0;36mload_C_mean\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_C_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mspamreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspamreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Simple_model/code/results/inf_treeSIR/CL_mean_weighted_pr_school_beta_0.360_betaT_0.000_mu_0.10_init_1.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"../Simple_model/code/results/inf_treeSIR/CL_mean_weighted_%s_beta_%.3f_betaT_0.000_mu_%.2f_init_1.csv\"%(dataset,beta,mu)\n",
    "C = load_C_mean(filename)\n",
    "# verify:\n",
    "if 2*len(edgelist) != len(C):\n",
    "    print('errore')\n",
    "r_simple, s_simple = obtain_r_s_indices(C,edgelist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.1\n",
    "\n",
    "if dataset == 'pr_school':\n",
    "    beta = 0.07\n",
    "    betaT = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Simplicial_model/code/results/inf_treeSIR/CL_mean_weighted_pr_school_beta_0.070_betaT_7.000_mu_0.10_init_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fbbccdcfe37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../Simplicial_model/code/results/inf_treeSIR/CL_mean_weighted_%s_beta_%.3f_betaT_%.3f_mu_%.2f_init_1.csv\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbetaT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_C_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../Simplicial_model/code/results/inf_treeSIR/CT_mean_weighted_%s_beta_%.3f_betaT_%.3f_mu_%.2f_init_1.csv\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbetaT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_C_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mCT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Progetti_post_doc/Infection_pattern-main/utils.py\u001b[0m in \u001b[0;36mload_C_mean\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_C_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mspamreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspamreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Simplicial_model/code/results/inf_treeSIR/CL_mean_weighted_pr_school_beta_0.070_betaT_7.000_mu_0.10_init_1.csv'"
     ]
    }
   ],
   "source": [
    "filename = \"../Simplicial_model/code/results/inf_treeSIR/CL_mean_weighted_%s_beta_%.3f_betaT_%.3f_mu_%.2f_init_1.csv\"%(dataset,beta,betaT,mu)\n",
    "CL = load_C_mean(filename)\n",
    "filename = \"../Simplicial_model/code/results/inf_treeSIR/CT_mean_weighted_%s_beta_%.3f_betaT_%.3f_mu_%.2f_init_1.csv\"%(dataset,beta,betaT,mu)\n",
    "CT = load_C_mean(filename)\n",
    "C = CL + CT\n",
    "# verify:\n",
    "if 2*len(edgelist) != len(C):\n",
    "    print('errore')\n",
    "r_simplicial, s_simplicial = obtain_r_s_indices(C,edgelist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'pr_school':\n",
    "    th = 0.1\n",
    "mu = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mu > 0:\n",
    "    filename = \"../Threshold_model/code/results/inf_treeSIR/C_mean_weighted_%s_th_%.2f_mu_%.3f.csv\"%(dataset,th,mu)\n",
    "else:\n",
    "    filename = \"../Threshold_model/code/results/inf_treeSI/C_mean_weighted_%s_th_%.2f.csv\"%(dataset,th)\n",
    "\n",
    "C = load_C_mean(filename)\n",
    "# verify:\n",
    "if 2*len(edgelist) != len(C):\n",
    "    print('errore')\n",
    "r_thresh, s_thresh = obtain_r_s_indices(C,edgelist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " G=nx.from_edgelist(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.sort(list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist_shape = []\n",
    "for link in edgelist:\n",
    "    edgelist_shape.append((link[0],link[1],edgelist[link]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.Graph()  \n",
    "#G.add_weighted_edges_from([(0, 1, 3.0), (1, 2, 7.5)])\n",
    "W.add_weighted_edges_from(edgelist_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_dict = nx.betweenness_centrality(W, weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for node in nodes:\n",
    "    b.append(b_dict[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dict = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for node in nodes:\n",
    "    c.append(c_dict[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dict = nx.clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = []\n",
    "for node in nodes:\n",
    "    cl.append(cl_dict[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dict = nx.pagerank(G, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for node in nodes:\n",
    "    p.append(p_dict[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_dict = dict(G.degree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for node in nodes:\n",
    "    k.append(k_dict[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dict = dict(W.degree(weight='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = []\n",
    "for node in nodes:\n",
    "    st.append(s_dict[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.empty((6, 6))\n",
    "\n",
    "M[0,0] = stats.pearsonr(k, s_simple)[0]\n",
    "M[0,1] = stats.pearsonr(k, r_simple)[0]\n",
    "\n",
    "M[0,2] = stats.pearsonr(k, s_simplicial)[0]\n",
    "M[0,3] = stats.pearsonr(k, r_simplicial)[0]\n",
    "\n",
    "M[0,4] = stats.pearsonr(k, s_thresh)[0]\n",
    "M[0,5] = stats.pearsonr(k, r_thresh)[0]\n",
    "#\n",
    "M[1,0] = stats.pearsonr(st, s_simple)[0]\n",
    "M[1,1] = stats.pearsonr(st, r_simple)[0]\n",
    "\n",
    "M[1,2] = stats.pearsonr(st, s_simplicial)[0]\n",
    "M[1,3] = stats.pearsonr(st, r_simplicial)[0]\n",
    "\n",
    "M[1,4] = stats.pearsonr(st, s_thresh)[0]\n",
    "M[1,5] = stats.pearsonr(st, r_thresh)[0]\n",
    "#\n",
    "M[2,0] = stats.pearsonr(c, s_simple)[0]\n",
    "M[2,1] = stats.pearsonr(c, r_simple)[0]\n",
    "\n",
    "M[2,2] = stats.pearsonr(c, s_simplicial)[0]\n",
    "M[2,3] = stats.pearsonr(c, r_simplicial)[0]\n",
    "\n",
    "M[2,4] = stats.pearsonr(c, s_thresh)[0]\n",
    "M[2,5] = stats.pearsonr(c, r_thresh)[0]\n",
    "#\n",
    "M[3,0] = stats.pearsonr(b, s_simple)[0]\n",
    "M[3,1] = stats.pearsonr(b, r_simple)[0]\n",
    "\n",
    "M[3,2] = stats.pearsonr(b, s_simplicial)[0]\n",
    "M[3,3] = stats.pearsonr(b, r_simplicial)[0]\n",
    "\n",
    "M[3,4] = stats.pearsonr(b, s_thresh)[0]\n",
    "M[3,5] = stats.pearsonr(b, r_thresh)[0]\n",
    "#\n",
    "M[4,0] = stats.pearsonr(p, s_simple)[0]\n",
    "M[4,1] = stats.pearsonr(p, r_simple)[0]\n",
    "\n",
    "M[4,2] = stats.pearsonr(p, s_simplicial)[0]\n",
    "M[4,3] = stats.pearsonr(p, r_simplicial)[0]\n",
    "\n",
    "M[4,4] = stats.pearsonr(p, s_thresh)[0]\n",
    "M[4,5] = stats.pearsonr(p, r_thresh)[0]\n",
    "#\n",
    "M[5,0] = stats.pearsonr(cl, s_simple)[0]\n",
    "M[5,1] = stats.pearsonr(cl, r_simple)[0]\n",
    "\n",
    "M[5,2] = stats.pearsonr(cl, s_simplicial)[0]\n",
    "M[5,3] = stats.pearsonr(cl, r_simplicial)[0]\n",
    "\n",
    "M[5,4] = stats.pearsonr(cl, s_thresh)[0]\n",
    "M[5,5] = stats.pearsonr(cl, r_thresh)[0]\n",
    "\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../figs/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "maxValue = max([max(M[n]) for n in range(len(M))])\n",
    "minValue = min([min(M[n]) for n in range(len(M))])\n",
    "\n",
    "plt.figure(figsize=(10,3.7))\n",
    "sns.heatmap(M,\n",
    "            xticklabels=['Simple\\nSpreader', 'Simple\\nReceiver','Simplicial\\nSpreader', 'Simplicial\\nReceiver','Threshold\\nSpreader', 'Threshold\\nReceiver'],\n",
    "            yticklabels=['Degree', 'Strength','Closeness','Betweenness','PageRank','Clustering'], \n",
    "            annot=True, \n",
    "            vmin=minValue, \n",
    "            vmax=maxValue,\n",
    "            linewidths=0.8,\n",
    "            cmap=\"viridis\",\n",
    "            cbar_kws={'label': 'Pearson\\'s correlation'})\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = folder + 'Centrality_r_s_corr_%s.pdf'%(dataset)\n",
    "plt.savefig(figname)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
